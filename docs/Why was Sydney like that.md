---
share: true
---

https://www.lesswrong.com/posts/tbJdxJMAiehewGpq2/impressions-from-base-gpt-4?commentId=ioZGEADiFKswoLCPP

- The commentary from Janus on using GPT-4 Base and the linked comment for Gwern paint a good picture of why Sydney was like that.
> This also sheds some light on [why Sydney](https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned?commentId=AAC8jKeDp6xqsZK2K) (a snapshot of GPT-4-base partway through training) would disagree with the user so much or be so stubborn. It's not that the MS training was responsible, but more characteristic of the base model.
- Gwern [links to another comment](https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned?commentId=AAC8jKeDp6xqsZK2K) of his that goes deeper into understanding what model Sydney was based on.

See also
- https://cyborgism.wiki/hypha/bing